{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":73233,"databundleVersionId":8112053,"sourceType":"competition"},{"sourceId":26406,"sourceType":"modelInstanceVersion","isSourceIdPinned":true,"modelInstanceId":22219},{"sourceId":26515,"sourceType":"modelInstanceVersion","isSourceIdPinned":true,"modelInstanceId":22315},{"sourceId":27701,"sourceType":"modelInstanceVersion","isSourceIdPinned":true,"modelInstanceId":23338}],"dockerImageVersionId":30673,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"raw","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-04-04T06:08:25.078264Z","iopub.execute_input":"2024-04-04T06:08:25.078735Z","iopub.status.idle":"2024-04-04T06:08:26.971418Z","shell.execute_reply.started":"2024-04-04T06:08:25.078704Z","shell.execute_reply":"2024-04-04T06:08:26.970459Z"}}},{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nimport torch.optim as optim\nimport torchvision.transforms as transforms\nimport torchvision.datasets as datasets\n\n# Check if GPU is available, and if not, use the CPU\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")","metadata":{"execution":{"iopub.status.busy":"2024-04-12T01:07:12.393544Z","iopub.execute_input":"2024-04-12T01:07:12.394405Z","iopub.status.idle":"2024-04-12T01:07:16.121193Z","shell.execute_reply.started":"2024-04-12T01:07:12.394373Z","shell.execute_reply":"2024-04-12T01:07:16.119935Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import numpy as np\nimport matplotlib.pyplot as plt\nimport os\nimport pickle\n\ndef load_cifar_batch(file):\n    with open(file, 'rb') as fo:\n        dict = pickle.load(fo, encoding='bytes')\n    return dict\n\n# Specify the folder where the CIFAR-10 batch files are\ncifar10_dir = '/kaggle/input/deep-learning-mini-project-spring-24-nyu/cifar-10-python/cifar-10-batches-py'\n\n# Load the label names\nmeta_data_dict = load_cifar_batch(os.path.join(cifar10_dir, 'batches.meta'))\nlabel_names = meta_data_dict[b'label_names']\n\n# Load one batch for demonstration (e.g., data_batch_1)\nbatch_1_dict = load_cifar_batch(os.path.join(cifar10_dir, 'data_batch_1'))\ntrain_images = batch_1_dict[b'data']\ntrain_labels = batch_1_dict[b'labels']\n\n# Reshape the images\ntrain_images = train_images.reshape((10000, 3, 32, 32)).transpose(0, 2, 3, 1)\n\n# Display the first 10 images and labels\nplt.figure(figsize=(20, 4))\nfor i in range(10):\n    plt.subplot(1, 10, i+1)\n    plt.imshow(train_images[i])\n    plt.title(label_names[train_labels[i]].decode('utf-8'))  # Decoding from bytes to string\n    plt.axis('off')\nplt.show()\n","metadata":{"execution":{"iopub.status.busy":"2024-04-12T01:07:16.124557Z","iopub.execute_input":"2024-04-12T01:07:16.125166Z","iopub.status.idle":"2024-04-12T01:07:17.654000Z","shell.execute_reply.started":"2024-04-12T01:07:16.125125Z","shell.execute_reply":"2024-04-12T01:07:17.652736Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Read the test file, note that it has no labels and needs to be used with your model inference to predict outputs.\n\ndef load_cifar_batch(file):\n    with open(file, 'rb') as fo:\n        batch = pickle.load(fo, encoding='bytes')\n    return batch\n\n# Load the batch\ncifar10_batch = load_cifar_batch('/kaggle/input/deep-learning-mini-project-spring-24-nyu/cifar_test_nolabels.pkl')\n\n# Extract images\nimages = cifar10_batch[b'data'].reshape(-1, 3, 32, 32).transpose(0, 2, 3, 1) ","metadata":{"execution":{"iopub.status.busy":"2024-04-12T01:07:17.655617Z","iopub.execute_input":"2024-04-12T01:07:17.656463Z","iopub.status.idle":"2024-04-12T01:07:18.171357Z","shell.execute_reply.started":"2024-04-12T01:07:17.656432Z","shell.execute_reply":"2024-04-12T01:07:18.170327Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Extract images and convert back to image format\nimages = cifar10_batch[b'data']\n# Reshape to (number of images, width, height, channels)\nimages = images.reshape((-1, 3, 32, 32)).transpose(0, 2, 3, 1)\n\n# Display the first 10 images\nplt.figure(figsize=(20, 4))\nfor i in range(10):\n    plt.subplot(1, 10, i+1)\n    plt.imshow(images[i])\n    plt.axis('off')\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2024-04-12T01:07:18.173170Z","iopub.execute_input":"2024-04-12T01:07:18.173658Z","iopub.status.idle":"2024-04-12T01:07:18.712109Z","shell.execute_reply.started":"2024-04-12T01:07:18.173617Z","shell.execute_reply":"2024-04-12T01:07:18.710362Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## teacher - widenet","metadata":{}},{"cell_type":"code","source":"import torchvision.models as models\nteacher = models.wide_resnet101_2(pretrained=False)\nteacher.fc = nn.Linear(teacher.fc.in_features, 10)\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nteacher = teacher.to(device)  ","metadata":{"execution":{"iopub.status.busy":"2024-04-12T02:02:11.070787Z","iopub.execute_input":"2024-04-12T02:02:11.071478Z","iopub.status.idle":"2024-04-12T02:02:13.459042Z","shell.execute_reply.started":"2024-04-12T02:02:11.071445Z","shell.execute_reply":"2024-04-12T02:02:13.458120Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"total_params_net = \"{:,}\".format(sum(p.numel() for p in teacher.parameters()))\nprint(f\"wide net parameters: {total_params_net}\")","metadata":{"execution":{"iopub.status.busy":"2024-04-12T02:02:13.461004Z","iopub.execute_input":"2024-04-12T02:02:13.461611Z","iopub.status.idle":"2024-04-12T02:02:13.469538Z","shell.execute_reply.started":"2024-04-12T02:02:13.461578Z","shell.execute_reply":"2024-04-12T02:02:13.468351Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import torch.optim as optim\nimport torchvision\nimport torchvision.transforms as transforms\nfrom torch.utils.data import DataLoader\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\n# Step 1: Load and preprocess the CIFAR-10 dataset\ntrain_trans=transforms.Compose([transforms.ToTensor(),\n           transforms.RandomCrop(32, padding=4),\n           transforms.RandomHorizontalFlip(),\n           transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\ntest_trans=transforms.Compose([transforms.ToTensor(),\n           transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n\ntrainset = torchvision.datasets.CIFAR10(root='./data', train=True, download=True, transform=train_trans)\ntrainloader = DataLoader(trainset, batch_size=128, shuffle=True, num_workers=16)\n\ntestset = torchvision.datasets.CIFAR10(root='./data', train=False, download=True, transform=test_trans)\ntestloader = DataLoader(testset, batch_size=int(128/4), shuffle=False, num_workers=16)\n\nclasses = ('plane', 'car', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck')\n\n# Step 2: Define the ResNet model\n#net = ResNet(BasicBlock, [2,2,2,2])  \nteacher = teacher.to('cuda' if torch.cuda.is_available() else 'cpu')\n\n# Step 3: Define a loss function and optimizer\ncriterion = nn.CrossEntropyLoss()\noptimizer = optim.SGD(teacher.parameters(), lr=0.1, momentum=0.9, weight_decay=5e-4)\n#optimizer = optim.Adam(teacher.parameters(), lr=0.001)\nscheduler = optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=200)\nbest_acc = 0.0\n# Step 4: Train the model\nfor epoch in range(200):  # number of epochs to train for\n    teacher.train()\n    running_loss = 0.0\n    for i, data in enumerate(trainloader, 0):\n        inputs, labels = data\n        inputs, labels = inputs.to('cuda'), labels.to('cuda')\n\n        optimizer.zero_grad()\n\n        outputs = teacher(inputs)\n        loss = criterion(outputs, labels)\n        loss.backward()\n        optimizer.step()\n\n        running_loss += loss.item()\n        if i % 100 == 99:  # print every 100 mini-batches\n            print('[Epoch: %d, Mini-batch: %5d] loss: %.3f' % (epoch + 1, i + 1, running_loss / 100))\n            running_loss = 0.0\n\n    scheduler.step()\n\n    # Optional: Print accuracy on the test set after each epoch\n    correct = 0\n    total = 0\n    with torch.no_grad():\n        teacher.eval()\n        for data in testloader:\n            images, labels = data\n            images, labels = images.to('cuda'), labels.to('cuda')\n            outputs = teacher(images)\n            _, predicted = torch.max(outputs.data, 1)\n            total += labels.size(0)\n            correct += (predicted == labels).sum().item()\n    acc = 100.0*correct/total\n    if(acc>best_acc):\n        #only save the best model\n        best_acc = acc\n        PATH = './best_teacher.pth'\n        torch.save(teacher.state_dict(), PATH)\n    print('Accuracy of the network on the 10000 test images: %d %%' % (100 * correct / total))\n\nprint('Finished Training')","metadata":{"execution":{"iopub.status.busy":"2024-04-12T02:02:15.612066Z","iopub.execute_input":"2024-04-12T02:02:15.612865Z","iopub.status.idle":"2024-04-12T02:04:34.240622Z","shell.execute_reply.started":"2024-04-12T02:02:15.612829Z","shell.execute_reply":"2024-04-12T02:04:34.238863Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## ResNet Architecture ","metadata":{}},{"cell_type":"code","source":"'''ResNet in PyTorch.\n\nFor Pre-activation ResNet, see 'preact_resnet.py'.\n\nReference:\n[1] Kaiming He, Xiangyu Zhang, Shaoqing Ren, Jian Sun\n    Deep Residual Learning for Image Recognition. arXiv:1512.03385\n'''\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\n\n\nclass BasicBlock(nn.Module):\n    expansion = 1\n\n    def __init__(self, in_planes, planes, stride=1):\n        super(BasicBlock, self).__init__()\n        # F_i: Convolutional kernel size for BasicBlock can be changed in the conv1 and conv2 lines\n        self.conv1 = nn.Conv2d(\n            in_planes, planes, kernel_size=3, stride=stride, padding=1, bias=False)\n        self.bn1 = nn.BatchNorm2d(planes)\n        self.conv2 = nn.Conv2d(planes, planes, kernel_size=3,\n                               stride=1, padding=1, bias=False)\n        self.bn2 = nn.BatchNorm2d(planes)\n\n        self.shortcut = nn.Sequential()\n        # K_i: Skip connection kernel size can be changed here if the condition is met\n        if stride != 1 or in_planes != self.expansion*planes:\n            self.shortcut = nn.Sequential(\n                nn.Conv2d(in_planes, self.expansion*planes,\n                          kernel_size=1, stride=stride, bias=False),\n                nn.BatchNorm2d(self.expansion*planes)\n            )\n\n    def forward(self, x):\n        out = F.relu(self.bn1(self.conv1(x)))\n        out = self.bn2(self.conv2(out))\n        out += self.shortcut(x)\n        out = F.relu(out)\n        return out\n\n\nclass Bottleneck(nn.Module):\n    expansion = 4\n\n    def __init__(self, in_planes, planes, stride=1):\n        super(Bottleneck, self).__init__()\n        self.conv1 = nn.Conv2d(in_planes, planes, kernel_size=1, bias=False)\n        self.bn1 = nn.BatchNorm2d(planes)\n        self.conv2 = nn.Conv2d(planes, planes, kernel_size=3,\n                               stride=stride, padding=1, bias=False)\n        self.bn2 = nn.BatchNorm2d(planes)\n        self.conv3 = nn.Conv2d(planes, self.expansion *\n                               planes, kernel_size=1, bias=False)\n        self.bn3 = nn.BatchNorm2d(self.expansion*planes)\n\n        self.shortcut = nn.Sequential()\n        if stride != 1 or in_planes != self.expansion*planes:\n            self.shortcut = nn.Sequential(\n                nn.Conv2d(in_planes, self.expansion*planes,\n                          kernel_size=1, stride=stride, bias=False),\n                nn.BatchNorm2d(self.expansion*planes)\n            )\n\n    def forward(self, x):\n        out = F.relu(self.bn1(self.conv1(x)))\n        out = F.relu(self.bn2(self.conv2(out)))\n        out = self.bn3(self.conv3(out))\n        out += self.shortcut(x)\n        out = F.relu(out)\n        return out\n\n\nclass ResNet(nn.Module):\n    def __init__(self, block, num_blocks, num_classes=10):\n        super(ResNet, self).__init__()\n        self.in_planes = 64\n\n        self.conv1 = nn.Conv2d(3, 64, kernel_size=3,\n                               stride=1, padding=1, bias=False)\n        self.bn1 = nn.BatchNorm2d(64)\n        # B_i: Number of blocks in each layer is set here through the num_blocks parameter\n        # C_i: Number of channels in each layer is set through the planes parameter\n        self.layer1 = self._make_layer(block, 100, num_blocks[0], stride=1) #64 #best64\n        self.layer2 = self._make_layer(block, 150, num_blocks[1], stride=2) #128 #best128\n        self.layer3 = self._make_layer(block, 215, num_blocks[2], stride=2) #256 #best160\n        self.layer4 = self._make_layer(block, 256, num_blocks[3], stride=2) #512 #best256\n        self.linear = nn.Linear(256*block.expansion, num_classes) #512 #best256\n\n    def _make_layer(self, block, planes, num_blocks, stride):\n        strides = [stride] + [1]*(num_blocks-1)\n        layers = []\n        for stride in strides:\n            layers.append(block(self.in_planes, planes, stride))\n            self.in_planes = planes * block.expansion\n        return nn.Sequential(*layers)\n\n    def forward(self, x):\n        out = F.relu(self.bn1(self.conv1(x)))\n        out = self.layer1(out)\n        out = self.layer2(out)\n        out = self.layer3(out)\n        out = self.layer4(out)\n        # P: Average pool kernel size is set here\n        out = F.avg_pool2d(out, 4)\n        out = out.view(out.size(0), -1)\n        out = self.linear(out)\n        return out","metadata":{"execution":{"iopub.status.busy":"2024-04-12T02:04:37.380283Z","iopub.execute_input":"2024-04-12T02:04:37.380636Z","iopub.status.idle":"2024-04-12T02:04:37.403943Z","shell.execute_reply.started":"2024-04-12T02:04:37.380610Z","shell.execute_reply":"2024-04-12T02:04:37.402958Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"net=ResNet(BasicBlock, [2,2, 2, 2]).cuda()","metadata":{"execution":{"iopub.status.busy":"2024-04-12T02:04:37.728454Z","iopub.execute_input":"2024-04-12T02:04:37.728970Z","iopub.status.idle":"2024-04-12T02:04:37.794924Z","shell.execute_reply.started":"2024-04-12T02:04:37.728942Z","shell.execute_reply":"2024-04-12T02:04:37.794163Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"total_params_net = \"{:,}\".format(sum(p.numel() for p in net.parameters()))\nprint(f\"modified resnet parameters: {total_params_net}\")","metadata":{"execution":{"iopub.status.busy":"2024-04-12T02:04:38.090874Z","iopub.execute_input":"2024-04-12T02:04:38.091825Z","iopub.status.idle":"2024-04-12T02:04:38.097101Z","shell.execute_reply.started":"2024-04-12T02:04:38.091790Z","shell.execute_reply":"2024-04-12T02:04:38.096011Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Training & Testing","metadata":{}},{"cell_type":"code","source":"teacher = models.wide_resnet101_2(pretrained=False)\nteacher.fc = nn.Linear(teacher.fc.in_features, 10)\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nteacher = teacher.to(device)  \nteacher.load_state_dict(torch.load('./best_teacher.pth',map_location=device))\nteacher.to(device)\nteacher.eval()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def distillation_loss(y_student, y_teacher, y_true, T=2.0, alpha=0.7):\n    KL_div = nn.KLDivLoss()(F.log_softmax(y_student/T, dim=1),\n                            F.softmax(y_teacher/T, dim=1)) * (alpha * T * T)\n    CE_loss = nn.CrossEntropyLoss()(y_student, y_true) * (1. - alpha)\n    return KL_div + CE_loss","metadata":{"execution":{"iopub.status.busy":"2024-04-12T02:04:50.332618Z","iopub.execute_input":"2024-04-12T02:04:50.333305Z","iopub.status.idle":"2024-04-12T02:04:50.339067Z","shell.execute_reply.started":"2024-04-12T02:04:50.333273Z","shell.execute_reply":"2024-04-12T02:04:50.338151Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import torch.optim as optim\nimport torchvision\nimport torchvision.transforms as transforms\nfrom torch.utils.data import DataLoader\n\n# Step 1: Load and preprocess the CIFAR-10 dataset\ntrain_trans=transforms.Compose([transforms.ToTensor(),\n           transforms.RandomCrop(32, padding=4),\n           transforms.RandomHorizontalFlip(),\n           transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\ntest_trans=transforms.Compose([transforms.ToTensor(),\n           transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n\ntrainset = torchvision.datasets.CIFAR10(root='./data', train=True, download=True, transform=train_trans)\ntrainloader = DataLoader(trainset, batch_size=128, shuffle=True, num_workers=16)\n\ntestset = torchvision.datasets.CIFAR10(root='./data', train=False, download=True, transform=test_trans)\ntestloader = DataLoader(testset, batch_size=int(128/4), shuffle=False, num_workers=16)\n\nclasses = ('plane', 'car', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck')\n\n# Step 2: Define the ResNet model\n#net = ResNet(BasicBlock, [2,2,2,2])  \nnet = net.to('cuda' if torch.cuda.is_available() else 'cpu')\n\n# Step 3: Define a loss function and optimizer\ncriterion = nn.CrossEntropyLoss()\n#optimizer = optim.SGD(net.parameters(), lr=0.1, momentum=0.9, weight_decay=5e-4)\noptimizer = optim.SGD(net.parameters(), lr=0.001)\nscheduler = optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=200)\nbest_acc = 0.0\nteacher.eval()\n# Step 4: Train the model\nfor epoch in range(200):  # number of epochs to train for\n    net.train()\n    running_loss = 0.0\n    for i, data in enumerate(trainloader, 0):\n        inputs, labels = data\n        inputs, labels = inputs.to('cuda'), labels.to('cuda')\n\n        optimizer.zero_grad()\n        with torch.no_grad():\n            teacher_outputs = teacher(inputs)\n        outputs = net(inputs)\n        loss = distillation_loss(outputs, teacher_outputs, labels)\n        #loss = criterion(outputs, labels)\n        loss.backward()\n        optimizer.step()\n\n        running_loss += loss.item()\n        if i % 100 == 99:  # print every 100 mini-batches\n            print('[Epoch: %d, Mini-batch: %5d] loss: %.3f' % (epoch + 1, i + 1, running_loss / 100))\n            running_loss = 0.0\n\n    scheduler.step()\n\n    # Optional: Print accuracy on the test set after each epoch\n    correct = 0\n    total = 0\n    with torch.no_grad():\n        net.eval()\n        for data in testloader:\n            images, labels = data\n            images, labels = images.to('cuda'), labels.to('cuda')\n            outputs = net(images)\n            _, predicted = torch.max(outputs.data, 1)\n            total += labels.size(0)\n            correct += (predicted == labels).sum().item()\n    acc = 100.0*correct/total\n    if(acc>best_acc):\n        #only save the best model\n        best_acc = acc\n        PATH = './cifar_net.pth'\n        torch.save(net.state_dict(), PATH)\n    print('Accuracy of the network on the 10000 test images: %d %%' % (100 * correct / total))\n\nprint('Finished Training')","metadata":{"execution":{"iopub.status.busy":"2024-04-12T02:04:50.496628Z","iopub.execute_input":"2024-04-12T02:04:50.496934Z","iopub.status.idle":"2024-04-12T02:05:40.654337Z","shell.execute_reply.started":"2024-04-12T02:04:50.496910Z","shell.execute_reply":"2024-04-12T02:05:40.653128Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import pickle\nimport torch\nfrom torchvision import transforms\nfrom torch.utils.data import DataLoader, TensorDataset\nimport torchvision\n\ndef load_cifar_batch(file):\n    with open(file, 'rb') as fo:\n        batch = pickle.load(fo, encoding='bytes')\n    return batch[b'data']  # Assuming the data is stored under this key\n\n# Preprocess and load the batch\nbatch_data = load_cifar_batch('/kaggle/input/deep-learning-mini-project-spring-24-nyu/cifar_test_nolabels.pkl')\nbatch_data = batch_data.reshape((-1, 3, 32, 32))  # Reshape to match the CIFAR-10 format\nbatch_data = batch_data / 255.0  # Normalize to [0, 1]\n\n# Apply the same transformations as for the test set\ntransform = transforms.Compose([\n    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),\n])\n\n# Convert numpy array to tensor\ntensor_data = torch.tensor(batch_data, dtype=torch.float32)\ntransformed_data = torch.stack([transform(img) for img in tensor_data])\n\n# Create a DataLoader\ndataset = TensorDataset(transformed_data)\ndataloader = DataLoader(dataset, batch_size=100, shuffle=False)\n\n#Load the best model\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nbest_model = ResNet(BasicBlock, [2,2,2,2]).cuda()\nbest_model.load_state_dict(torch.load('./cifar_net.pth',map_location=device))\nbest_model.to(device)\nbest_model.eval()\n\n# Inference\n# Inference with ID and prediction\npredictions_with_id = []\nwith torch.no_grad():\n    for batch_idx, data in enumerate(dataloader):\n        inputs = data[0].cuda()\n        outputs = best_model(inputs)\n        _, predicted = torch.max(outputs.data, 1)\n        batch_predictions = predicted.cpu().numpy()\n\n        # Add ID and prediction to the list\n        start_id = batch_idx * dataloader.batch_size\n        for i, pred in enumerate(batch_predictions):\n            predictions_with_id.append((start_id + i, int(pred)))\n\n# predictions_with_id now contains tuples of (image_id, predicted_class)\n","metadata":{"execution":{"iopub.status.busy":"2024-04-12T02:00:40.417974Z","iopub.status.idle":"2024-04-12T02:00:40.418313Z","shell.execute_reply.started":"2024-04-12T02:00:40.418155Z","shell.execute_reply":"2024-04-12T02:00:40.418168Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import csv\n\ncsv_file_path = 'cifar_predictions.csv'\nwith open(csv_file_path, mode='w', newline='') as file:\n    writer = csv.writer(file)\n    writer.writerow([\"ID\", \"Labels\"])  # Writing header\n    writer.writerows(predictions_with_id)\n\n","metadata":{"execution":{"iopub.status.busy":"2024-04-10T21:55:09.958956Z","iopub.status.idle":"2024-04-10T21:55:09.959285Z","shell.execute_reply.started":"2024-04-10T21:55:09.959127Z","shell.execute_reply":"2024-04-10T21:55:09.959140Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}